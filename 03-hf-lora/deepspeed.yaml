name: language modeling deepspeed
debug: false
environment:
  environment_variables:
    - NCCL_DEBUG=INFO
    - HF_HOME=/hf_cache
    # You may need to modify this to match your network configuration.
    #- NCCL_SOCKET_IFNAME=ens,eth,ib
  image:
    gpu: determinedai/environments-dev:python-3.10-pytorch-2.0-deepspeed-0.10.0-smartsim
resources:
  slots_per_trial: 2
bind_mounts:
  # Fill in shared_fs path for hf cache to speed up model loading in subsequent runs.
  - host_path: FILL_IN_SHARED_FS_PATH_FOR_HF_CACHE
    container_path: /hf_cache
searcher:
  name: single
  max_length:
    batches: 100
  metric: eval_loss
hyperparameters:
  deepspeed_config: ds_configs/ds_config_stage_1.json
  training_arguments:
    learning_rate: 1e-5
entrypoint: >-
  python -m determined.launch.deepspeed
  python run_clm.py
  --model_name_or_path lmsys/vicuna-7b-v1.5
  --dataset_name wikitext
  --dataset_config_name wikitext-2-raw-v1
  --do_train
  --do_eval
  --deepspeed ds_configs/ds_config_stage_3.json
  --torch_dtype float16
  --num_train_epochs 5
  --logging_strategy steps
  --logging_steps 10
  --output_dir /tmp/test-clm
  --evaluation_strategy steps
  --eval_steps 10
  --save_total_limit 3
  --seed 1337
  --save_strategy steps
  --save_steps 20
  --per_device_train_batch_size 1
  --per_device_eval_batch_size 1
  --trust_remote_code true
  --fp16
max_restarts: 0
